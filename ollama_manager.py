# ollama_manager.py
import requests

def get_ollama_models(base_url="http://localhost:11434"):
    """R√©cup√®re la liste des mod√®les disponibles dans Ollama."""
    try:
        response = requests.get(f"{base_url.rstrip('/')}/api/tags", timeout=5)
        if response.status_code == 200:
            data = response.json()
            return [model["name"] for model in data.get("models", []) if "name" in model]
    except Exception as e:
        print(f"‚ö†Ô∏è FMJ Llm Config: impossible de charger les mod√®les : {e}")
    return ["llama3", "qwen3", "moondream", "llava", "phi3"]

class FMJLlmConfigNode:
    """‚öôÔ∏è FMJ Llm Config ‚Äî Configure l'URL Ollama et s√©lectionne un mod√®le."""

    @classmethod
    def INPUT_TYPES(cls):
        # Utilise l'URL par d√©faut pour charger les mod√®les
        models = get_ollama_models()
        if not models:
            models = ["llama3"]
        return {
            "required": {
                "ollama_url": ("STRING", {"default": "http://localhost:11434"}),
                "selected_model": (models, {"default": models[0]}),
            }
        }

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("model_name", "ollama_url")
    FUNCTION = "output_config"
    CATEGORY = "üåÄFMJ"

    def output_config(self, ollama_url, selected_model):
        return (selected_model, ollama_url)


# üî∏ Enregistrement du n≈ìud
NODE_CLASS_MAPPINGS = {
    "FMJLlmConfigNode": FMJLlmConfigNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "FMJLlmConfigNode": "‚öôÔ∏è FMJ Llm Config"  # üëà Nom mis √† jour
}
