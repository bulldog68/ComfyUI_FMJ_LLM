## üì¶ Package : **ComfyUI_FMJ_LLM**
> **Auteur** : FMJ  
> **Description** : N≈ìuds avanc√©s pour l‚Äôinteraction avec **Ollama** (texte, vision, √©dition d‚Äôimage), avec gestion dynamique des prompts via CSV.
<img width="1163" height="1209" alt="Capture d‚Äô√©cran du 2025-11-10 13-50-10" src="https://github.com/user-attachments/assets/91e2b3b6-f1b8-42bb-829c-d06b63daa545" />
# üß† **ComfyUI FMJ LLM** ‚Äî Int√©gration Ollama native dans ComfyUI

> **G√©n√©rez, am√©liorez, analysez et d√©crivez vos prompts avec l‚ÄôIA locale ‚Äî directement dans ComfyUI.**

Ce pack de n≈ìuds personnalis√©s permet d‚Äô**int√©grer Ollama** (mod√®les comme `llama3`, `qwen3`, `moondream`, `llava`, etc.) **directement dans vos workflows ComfyUI**, sans d√©pendance externe ni service cloud. Tout reste **100 % local**.

---

## üåü Fonctionnalit√©s principales

### üîπ 1. **G√©n√©ration de prompts textuels avanc√©s** (`ü¶ôFMJ Ollama Prompt Generator`)
G√©n√©rez des r√©ponses avanc√©es √† partir de n‚Äôimporte quel mod√®le Ollama (notamment **Qwen3**, Llama 3.2, Mistral, etc.) en combinant un **texte d‚Äôentr√©e** avec un **prompt syst√®me personnalis√©** charg√© depuis un fichier CSV ou saisi manuellement. Id√©al pour automatiser des t√¢ches comme la r√©√©criture, le r√©sum√©, la traduction, l‚Äôanalyse de texte, ou toute interaction structur√©e avec un LLM.

> ‚úÖ Compatible avec tous les mod√®les **chat-based** via l‚Äôendpoint `/api/chat` d‚ÄôOllama  
> ‚úÖ Optimis√© pour **Qwen3** (y compris les mod√®les *thinking models*)  
> ‚úÖ Supporte les prompts syst√®me dynamiques via CSV  
> ‚úÖ Int√©gration transparente dans **ComfyUI**

---

## üì• Entr√©es

| Nom | Type | Description |
|-----|------|-------------|
| **`text`** *(obligatoire)* | `STRING` | Le texte √† traiter par le mod√®le (ex: un paragraphe √† r√©sumer, une phrase √† corriger, une question √† r√©pondre). Doit √™tre connect√© depuis un n≈ìud en amont. |
| **`prompt_style`** | `LIST` | S√©lectionnez un style de prompt pr√©d√©fini depuis vos fichiers CSV (dossier `csv/`). Chaque style correspond √† une instruction syst√®me sp√©cifique (ex: "r√©sum√©", "correction", "cr√©ation de sc√©nario"). |
| **`model_name`** | `STRING` | Nom du mod√®le Ollama √† utiliser. Ex: `qwen3:2b`, `llama3.2`, `mistral`, `phi3`, etc. **Doit √™tre pr√©sent localement** (`ollama list`). |
| **`ollama_url`** | `STRING` | URL de l‚ÄôAPI Ollama. Par d√©faut : `http://localhost:11434`. Modifiez si Ollama tourne sur une autre machine ou un port personnalis√©. |
| **`max_tokens`** | `INT` | Nombre maximum de tokens √† g√©n√©rer. Valeur typique : `256` √† `2048`. Pour Qwen3, des valeurs √©lev√©es (jusqu‚Äô√† `16384`) sont possibles. |
| **`temperature`** | `FLOAT` | Contr√¥le la cr√©ativit√© de la r√©ponse. `0.0` = d√©terministe, `0.7` = √©quilibr√©, `1.0+` = tr√®s cr√©atif. |
| **`seed`** | `INT` | Graine al√©atoire pour la reproductibilit√©. `0` = al√©atoire √† chaque appel. |
| **`keep_alive`** | `INT` | Dur√©e (en minutes) pendant laquelle le mod√®le reste en m√©moire apr√®s utilisation. `-1` = toujours charg√©, `0` = d√©charger imm√©diatement. |
| **`request_timeout`** | `INT` | **(Nouveau)** D√©lai maximal d‚Äôattente (en secondes) avant d‚Äôabandonner la requ√™te. **Crucial pour Qwen3** (mode raisonnement lent). Valeur recommand√©e : `300` (5 min). |
| **`override_prompt`** *(facultatif)* | `STRING` | Remplace enti√®rement le prompt syst√®me s√©lectionn√©. Si ce champ n‚Äôest **pas vide**, il ignore `prompt_style`. Utile pour des instructions ponctuelles. |
| **`disable_thinking`** *(facultatif)* | `BOOLEAN` | **(Nouveau)** Si activ√© (**ON**), d√©sactive la trace de raisonnement interm√©diaire de Qwen3 (`think: false`). **Recommand√©** pour obtenir une r√©ponse directe sans balises `<think>...<think>`. |

---

## üì§ Sorties

| Nom | Type | Description |
|-----|------|-------------|
| **`response`** | `STRING` | La r√©ponse g√©n√©r√©e par le mod√®le, pr√™te √† √™tre utilis√©e dans d‚Äôautres n≈ìuds (ex: sauvegarde, affichage, traitement ult√©rieur). |
| **`debug_info`** | `STRING` | Informations de d√©bogage : statut, mod√®le utilis√©, timeout, style de prompt. Utile pour diagnostiquer les erreurs (ex: r√©ponse vide, mod√®le non trouv√©, timeout). |

---

## üìÅ Configuration : Fichiers CSV

Le n≈ìud charge automatiquement **tous les fichiers `.csv`** dans le sous-dossier `csv/` situ√© **au m√™me niveau que ce script**.

Chaque fichier CSV doit avoir **exactement deux colonnes** :

- `prompt_style` : nom unique du style (affich√© dans le menu d√©roulant)
- `system_prompt` : instruction syst√®me compl√®te envoy√©e au LLM

### Exemple de fichier : `csv/writing_prompts.csv`

```csv
prompt_style,system_prompt
qwen_edit,Tu es un √©diteur expert. Corrige, am√©liore et reformule le texte suivant pour plus de clart√©, de fluidit√© et de professionnalisme. Ne rajoute rien.
qwen_summary,R√©sume le texte suivant en 2-3 phrases maximum, en fran√ßais, en conservant les id√©es essentielles.
creative_story,√âcris une courte histoire cr√©ative (50 mots) bas√©e sur le th√®me suivant :
```

> üí° Ajoutez autant de fichiers CSV que vous voulez (`seo.csv`, `code.csv`, etc.). Le n≈ìud les fusionne automatiquement.

---

## ‚ö†Ô∏è Remarques importantes

- **Qwen3 est lent** : Augmentez `request_timeout` si vous obtenez des erreurs de timeout.
- **Pas de r√©ponse ?** V√©rifiez :
  1. Que le mod√®le est bien install√© (`ollama list`)
  2. Que le CSV contient bien le `prompt_style` s√©lectionn√©
  3. Que `disable_thinking` est **activ√©** (**ON**) pour √©viter les sorties vides dues au parsing de `<think>`
- **Le n≈ìud utilise `/api/chat`**, pas `/api/generate` ‚Üí il **ne fonctionne pas avec des mod√®les non-chat** (ex: anciens mod√®les GGUF sans template de chat).

---

## üß™ Exemple d‚Äôutilisation dans ComfyUI

1. Connectez un n≈ìud **Text** √† `text`.
2. S√©lectionnez `qwen_edit` dans `prompt_style`.
3. Laissez `model_name = qwen3:2b`.
4. Activez `disable_thinking = ON`.
5. R√©glez `request_timeout = 300`.
6. La sortie `response` contiendra le texte √©dit√© par Qwen3.

---
---

### üîπ 2. **Analyse d‚Äôimage par IA vision** (`üëÅÔ∏è FMJ Llm Ollama Vision`)

Analysez des images avec des mod√®les multimodaux d‚ÄôOllama (**Qwen3-VL**, Llava, BakLLaVA, etc.) en combinant une **image d‚Äôentr√©e** avec une **instruction syst√®me personnalis√©e** charg√©e depuis un fichier CSV ou saisie manuellement. G√©n√©rez des descriptions d√©taill√©es, du texte alternatif, des analyses artistiques, ou toute autre interpr√©tation visuelle pilot√©e par LLM.

> ‚úÖ Compatible avec tous les mod√®les **multimodaux via `/api/chat`**  
> ‚úÖ Optimis√© pour **Qwen3-VL** (y compris son *mode raisonnement*)  
> ‚úÖ Supporte les instructions syst√®me dynamiques via CSV  
> ‚úÖ Int√©gration transparente dans **ComfyUI**

---

## üì• Entr√©es

| Nom | Type | Description |
|-----|------|-------------|
| **`image`** *(obligatoire)* | `IMAGE` | L‚Äôimage √† analyser, provenant d‚Äôun n≈ìud d‚Äôimage en amont (ex: Load Image, KSampler, etc.). |
| **`description_type`** | `LIST` | S√©lectionnez un type d‚Äôanalyse pr√©d√©fini depuis vos fichiers CSV (dossier `csvv/`). Chaque type correspond √† une instruction syst√®me sp√©cifique (ex: "description d√©taill√©e", "texte alternatif"). |
| **`model_name`** | `STRING` | Nom du mod√®le multimodal Ollama. Ex: `qwen3-vl:2b`, `llava`, `bakllava`, etc. **Doit √™tre install√© localement** (`ollama list`). |
| **`ollama_url`** | `STRING` | URL de l‚ÄôAPI Ollama. Par d√©faut : `http://localhost:11434`. Modifiez en cas d‚Äôh√©bergement distant. |
| **`max_tokens`** | `INT` | Nombre maximum de tokens √† g√©n√©rer. Valeur typique : `256‚Äì1024`. Qwen3-VL supporte jusqu‚Äô√† `16384`. |
| **`temperature`** | `FLOAT` | Contr√¥le la cr√©ativit√©. `0.0` = d√©terministe, `0.7` = √©quilibr√©. |
| **`seed`** | `INT` | Graine al√©atoire pour la reproductibilit√©. `0` = al√©atoire. |
| **`keep_alive`** | `INT` | Dur√©e (en minutes) de mise en cache du mod√®le. `-1` = toujours en m√©moire, `0` = d√©charger apr√®s usage. |
| **`request_timeout`** | `INT` | **(Nouveau)** D√©lai maximal d‚Äôattente (en secondes). **Tr√®s important pour Qwen3-VL** (peut √™tre lent). Valeur recommand√©e : `300` (5 min). |
| **`override_prompt`** *(facultatif)* | `STRING` | Remplace l‚Äôinstruction syst√®me s√©lectionn√©e. Si non vide, ignore `description_type`. |
| **`disable_thinking`** *(facultatif)* | `BOOLEAN` | **(Nouveau)** Si **ON**, d√©sactive la trace de raisonnement de Qwen3-VL (`think: false`). **Fortement recommand√©** pour obtenir une r√©ponse directe sans balises `\<think>`. |

---

## üì§ Sorties

| Nom | Type | Description |
|-----|------|-------------|
| **`description`** | `STRING` | Le texte g√©n√©r√© par le mod√®le √† partir de l‚Äôimage et de l‚Äôinstruction. Pr√™t pour affichage, sauvegarde ou traitement ult√©rieur. |
| **`debug_info`** | `STRING` | Informations de diagnostic : statut, mod√®le utilis√©, type d‚Äôanalyse, timeout. Utile en cas d‚Äôerreur ou de r√©ponse vide. |

---

## üìÅ Configuration : Fichiers CSV

Le n≈ìud charge automatiquement tous les fichiers `.csv` du sous-dossier **`csvv/`** situ√© au m√™me niveau que ce script.

Chaque fichier doit contenir **exactement deux colonnes** :

- `description_type` : nom du type d‚Äôanalyse (affich√© dans le menu d√©roulant)
- `system_prompt` : instruction syst√®me compl√®te pour guider l‚Äôanalyse visuelle

### Exemple : `csvv/vision_prompts.csv`

```csv
description_type,system_prompt
detailed_vision,Donne une description d√©taill√©e, objective et compl√®te de l'image. Mentionne les objets, les couleurs, les actions, le contexte et l'humeur.
alt_text,G√©n√®re un texte alternatif concis (max 120 caract√®res) pour l'accessibilit√© web.
art_analysis,Analyse cette ≈ìuvre comme un critique d'art : style, composition, √©motion, √©poque possible.
product_caption,√âcris une l√©gende marketing engageante pour ce produit (max 20 mots).
```

> üí° Vous pouvez cr√©er plusieurs fichiers (`accessibility.csv`, `art.csv`, etc.). Le n≈ìud les fusionne automatiquement.

---

## ‚ö†Ô∏è Remarques importantes

- **Qwen3-VL est lent** : Augmentez `request_timeout` si vous obtenez des erreurs de timeout.
- **Pas de description ?** V√©rifiez :
  1. Que le mod√®le est bien install√© (`ollama list`)
  2. Que le fichier CSV contient le `description_type` s√©lectionn√©
  3. Que `disable_thinking` est **activ√© (ON)** ‚Äî c‚Äôest essentiel pour √©viter les r√©ponses vides dues au mode *reasoning*.
- Ce n≈ìud utilise **`/api/chat`**, pas `/api/generate` ‚Üí il **ne fonctionne pas avec des mod√®les non-chat ou non-multimodaux**.

---

## üß™ Exemple d‚Äôutilisation dans ComfyUI

1. Connectez une image √† `image`.
2. S√©lectionnez `alt_text` dans `description_type`.
3. Utilisez `model_name = qwen3-vl:2b`.
4. Activez `disable_thinking = ON`.
5. R√©glez `request_timeout = 300`.
6. La sortie `description` contiendra un texte alternatif pr√™t pour le web.

---

---

### üîπ 3. **Gestion centralis√©e d‚ÄôOllama** (`‚öôÔ∏è FMJ Llm Config`)
- S√©lectionnez **l‚ÄôURL d‚ÄôOllama** (par d√©faut : `http://localhost:11434`)
- Liste **dynamique des mod√®les install√©s** ‚Üí choisissez celui √† utiliser
- Branchez la sortie vers les autres n≈ìuds ‚Üí configuration **unifi√©e et modulaire**

---

### üîπ 4. **Nettoyage m√©moire √† la demande** (`üßπ FMJ Unload All LLM`)
- **D√©charge tous les mod√®les** d‚ÄôOllama de la m√©moire ‚Üí lib√®re la RAM/VRAM
- Id√©al **avant un long workflow** ou pour **changer de mod√®le lourd**
- Aucun risque de rechargement automatique

---

## üì¶ Compatibilit√©

- ‚úÖ **Ollama ‚â• v0.13** (test√© sur Linux, Windows)

---

> üí° **Tout tourne en local.** Vos images, vos prompts, vos donn√©es restent **sur votre machine**.
> üí° **Installer Ollama avant le node. https://ollama.com/
